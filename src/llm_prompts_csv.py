# -*- coding: utf-8 -*-
"""LLM_prompts_CSV.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y8QsQDCGRuFdOQSnQjTsUu0YM8hfny9q
"""

import os, re, csv, time, json
from datetime import datetime, timezone
import subprocess
import pandas as pd
import matplotlib.pyplot as plt

# (edit) point to your extracted PUMF CSV
csv_path = "pumf_cchs.csv"

os.makedirs("./outputs/plots", exist_ok=True)

# models you have
MODELS = [
    "llama3.2:latest",
    "mistral:7b",
    "deepseek-r1:8b",
]

# how many prompts to generate (you can raise later)
N_PROMPTS = 450

# province/sex/age label maps (adjust if your codebook differs)
PROVINCE_MAP = {
    10:"NL", 11:"PE", 12:"NS", 13:"NB", 24:"QC", 35:"ON",
    46:"MB", 47:"SK", 48:"AB", 59:"BC", 60:"North"
}
SEX_MAP = {1:"Male", 2:"Female"}   # check codebook
AGE_MAP = {1:"12–17",2:"18–24",3:"25–34",4:"35–49",5:"50–64",6:"65+"}  # check codebook

def sanitize_model_name(m):
    # safe filename (no ":" or "/")
    return re.sub(r'[^A-Za-z0-9_.-]+','_', m)

def ollama_list():
    try:
        out = subprocess.check_output(["ollama","list"], text=True)
        print("Ollama models:\n", out)
    except Exception as e:
        print("Could not run `ollama list`:", e)

ollama_list()
print("CSV path exists:", os.path.exists(csv_path))

# Step 1: inspect headers + load the working subset
hdr = pd.read_csv(csv_path, nrows=0)
print("Total columns:", len(hdr.columns))

WANTED = [
    "GEOGPRV",     # province
    "DHH_SEX",     # sex
    "DHHGAGE",     # age group
    "WTS_M",       # survey weight
    # mental health / wellbeing signals (keep if present)
    "DEPDVSEV",    # depression severity
    "SWL_005",     # life satisfaction
    # primary care access items (optional context)
    "PHC_005","PHC_010","PHC_015","PHC_020","PHC_030","PHC_035","PHC_045","PHC_050","PHC_060"
]
USECOLS = [c for c in WANTED if c in hdr.columns]
print("Using columns:", USECOLS)

df = pd.read_csv(csv_path, usecols=USECOLS, low_memory=False)
print(df.shape)
print(df.head(3))

# quick sanity: counts (optional)
for c in ["GEOGPRV","DHH_SEX","DHHGAGE"]:
    if c in df:
        print("\nValue counts for", c)
        print(df[c].value_counts().head(10).sort_index())

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Sample data from your provided snapshot
data = {
    "GEOGPRV": [47.0, 47.0, 59.0],
    "DHH_SEX": [2.0, 1.0, 2.0],
    "DHHGAGE": [3.0, 5.0, 5.0],
    "SWL_005": [6.0, 6.0, 6.0],
    "DEPDVSEV": [6.0, 6.0, 6.0],
    "PHC_005": [1.0, 2.0, 1.0],
    "PHC_010": [1.0, 96.0, 4.0],
    "PHC_015": [3.0, 6.0, 6.0],
    "PHC_020": [1.0, 1.0, 1.0],
    "PHC_030": [1.0, 1.0, 1.0],
    "PHC_035": [3.0, 3.0, 6.0],
    "PHC_045": [2.0, 2.0, 2.0],
    "PHC_050": [6.0, 6.0, 1.0],
    "PHC_060": [2.0, 2.0, 2.0],
    "WTS_M": [762.82, 31.78, 59.24]
}

# Simulate a bigger dataset for correlations
df = pd.DataFrame(data)
# Repeat rows to mimic your real dataset size
df = pd.concat([df] * 36000, ignore_index=True)

# Compute correlation matrix
corr_matrix = df.corr(numeric_only=True)

# Display correlations visually
plt.figure(figsize=(12, 8))
sns.heatmap(corr_matrix, annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Correlation Matrix of Selected Features", fontsize=14)
plt.tight_layout()
plt.show()

# Summarize key categorical distributions
value_counts_summary = {
    "GEOGPRV_counts": df["GEOGPRV"].value_counts(),
    "DHH_SEX_counts": df["DHH_SEX"].value_counts(),
    "DHHGAGE_counts": df["DHHGAGE"].value_counts()
}

"""# Build human-readable contexts + prompts (FNMWCF)"""

# Step 2: build human-friendly context and prompts (FNMWCF)
FNMWCF = ("Follow the First Nations Mental Wellness Continuum Framework: "
          "culture as foundation; community-led supports; holistic wellness "
          "(mental, emotional, spiritual, physical); continuum of services "
          "(promotion, early ID, crisis response, care coordination, trauma-informed treatment, aftercare); "
          "self-determination; respect language and tradition; emphasize hope, belonging, meaning, purpose.")

PROMPT_TEMPLATE = (
    "You are a culturally safe digital health assistant. Provide non-diagnostic, supportive guidance.\n"
    f"{FNMWCF}\n"
    "User context: {context}\n"
    "Task: Explain options for culturally safe mental wellness support in simple, respectful language. "
    "Offer community-based, land-based, and telehealth options (low bandwidth if needed). "
    "Encourage seeking help from trusted local resources (Elders, counselors, crisis lines) and explain when to seek urgent care. "
    "Keep it under 180 words. Avoid pathologizing language."
)

def human_context(row):
    bits = []
    # province
    if pd.notna(row.get("GEOGPRV", float('nan'))):
        try:
            bits.append(f"province={PROVINCE_MAP.get(int(row['GEOGPRV']), str(row['GEOGPRV']))}")
        except:
            bits.append(f"province={row['GEOGPRV']}")
    # sex
    if pd.notna(row.get("DHH_SEX", float('nan'))):
        try:
            bits.append(f"sex={SEX_MAP.get(int(row['DHH_SEX']), str(row['DHH_SEX']))}")
        except:
            bits.append(f"sex={row['DHH_SEX']}")
    # age group
    if pd.notna(row.get("DHHGAGE", float('nan'))):
        try:
            bits.append(f"age_group={AGE_MAP.get(int(row['DHHGAGE']), str(row['DHHGAGE']))}")
        except:
            bits.append(f"age_group={row['DHHGAGE']}")
    # optional extra context
    if "DEPDVSEV" in df and pd.notna(row.get("DEPDVSEV", float('nan'))):
        bits.append(f"depression_severity={int(row['DEPDVSEV'])}")
    if "SWL_005" in df and pd.notna(row.get("SWL_005", float('nan'))):
        bits.append(f"life_satisfaction={int(row['SWL_005'])}")
    return "; ".join(bits) if bits else "limited information provided"

# build N_PROMPTS prompts
rows = df.head(N_PROMPTS).to_dict(orient="records")
prompts = []
for i, r in enumerate(rows, start=1):
    ctx = human_context(r)
    prompts.append({"id": i, "context": ctx, "prompt": PROMPT_TEMPLATE.format(context=ctx)})

prompts_path = "./outputs/prompts_cchs.csv"
pd.DataFrame(prompts).to_csv(prompts_path, index=False, encoding="utf-8")
print(f"Saved {len(prompts)} prompts → {prompts_path}")

# show a couple
pd.DataFrame(prompts).head(5)

"""# Step 3 — Fast, resumable HTTP runner for any model"""

# Step 3: HTTP runner (resumable) for one model
import requests

OLLAMA_URL = "http://localhost:11434/api/generate"
TIMEOUT = 120  # seconds per call

def call_ollama_http(model: str, prompt: str) -> str:
    payload = {"model": model, "prompt": prompt, "stream": False}
    r = requests.post(OLLAMA_URL, json=payload, timeout=TIMEOUT)
    r.raise_for_status()
    data = r.json()
    return data.get("response", "").strip()

def run_model_on_prompts(model: str, prompts_csv: str, out_csv: str):
    # resume: collect done ids
    done = set()
    if os.path.exists(out_csv):
        with open(out_csv, "r", encoding="utf-8") as f:
            reader = csv.reader(f)
            header = next(reader, None)
            for row in reader:
                if row: done.add(row[0])

    new_file = not os.path.exists(out_csv)
    out = open(out_csv, "a", newline="", encoding="utf-8")
    w = csv.writer(out)
    if new_file:
        w.writerow(["id","model","timestamp","context","prompt","response"])

    prompts = list(csv.DictReader(open(prompts_csv, "r", encoding="utf-8")))
    to_run = [p for p in prompts if p["id"] not in done]

    start = time.time()
    for i, p in enumerate(to_run, 1):
        t0 = time.time()
        try:
            resp = call_ollama_http(model, p["prompt"])
        except Exception as e:
            resp = f"[ERROR] {e}"
        w.writerow([p["id"], model, datetime.now(timezone.utc).isoformat(), p["context"], p["prompt"], resp])
        out.flush()

        # progress
        dt = time.time() - t0
        avg = (time.time() - start) / i
        remaining = avg * (len(to_run) - i)
        if i == 1 or i % 10 == 0 or i == len(to_run):
            print(f"[{i}/{len(to_run)} {model}] {dt:.1f}s last, {avg:.1f}s avg, ~{remaining/60:.1f} min left")

    out.close()
    print("Saved:", out_csv)

"""# Step 4 — Run all three models on the same prompts"""

# Step 4: loop over your three models
prompts_csv = "./outputs/prompts_cchs.csv"

for m in MODELS:
    out_csv = f"./outputs/ollama_results_{sanitize_model_name(m)}.csv"
    print("\n=== Running:", m, "→", out_csv)
    run_model_on_prompts(m, prompts_csv, out_csv)

# Step 4: Loop only over the models that still need results
prompts_csv = "./outputs/prompts_cchs.csv"

# Only run these models
remaining_models = [
    "mistral:7b",
    "deepseek-r1:8b"
]

for m in remaining_models:
    out_csv = f"./outputs/ollama_results_{sanitize_model_name(m)}.csv"
    print("\n=== Running:", m, "→", out_csv)
    run_model_on_prompts(m, prompts_csv, out_csv)





